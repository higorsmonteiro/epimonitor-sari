{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf7ddc5-8d34-4f17-a4bd-20dbfca8f626",
   "metadata": {},
   "source": [
    "# **Data Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e00b1d-cad4-475b-973e-04c4dc2e8bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTables is not installed. No support for HDF output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "from simpledbf import Dbf5\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc19559b-2653-4d3a-b3d8-a48c31507da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import Table, MetaData\n",
    "from sqlalchemy import select, insert, update, text, inspect\n",
    "from sqlalchemy import Column, DateTime, Integer, Numeric, String, Sequence, ForeignKey, CheckConstraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "754b5299-7331-4a19-bc2f-3c3fea222ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.exc import IntegrityError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef360b7e-48b4-425c-a788-38b7ba2ba17d",
   "metadata": {},
   "source": [
    "## Data sample\n",
    "\n",
    " - SIVEP-Gripe (500 records)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43dc550-483e-45ac-bbcf-b80703cb48bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = os.path.join(os.environ[\"HOMEPATH\"], \"Documents\", \"data\")\n",
    "siveppath = os.path.join(basepath, \"SIVEP-GRIPE\", \"MILLENA_14JUN2023\")\n",
    "fname = \"SRAGHOSPITALIZADO1930520_00.dbf\"\n",
    "\n",
    "sivep_df = Dbf5(os.path.join(siveppath, fname), codec=\"latin\").to_dataframe()\n",
    "sample_df = sivep_df.sample(n=500, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46de645-001a-4491-9658-91503a7de928",
   "metadata": {},
   "source": [
    "## **Define Warehouse**\n",
    "\n",
    "**Data Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "ae2fc4bd-6595-41e5-b428-bf65bc7b278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class smart_dict(dict):\n",
    "    def __missing__(self, x):\n",
    "        if pd.notna(x):\n",
    "            return x\n",
    "        return None\n",
    "\n",
    "class SivepGripe:\n",
    "    def __init__(self, metadata):\n",
    "        self.metadata = metadata\n",
    "    \n",
    "    def define(self):\n",
    "        # --> Data model\n",
    "        tb_name = 'sivep_gripe'\n",
    "        self.sivep_warehouse = Table(\n",
    "            tb_name, self.metadata,\n",
    "            Column(\"ID_SIVEP\", String, primary_key=True),\n",
    "            Column(\"DATA_NOTIFICACAO\", DateTime, nullable=False),\n",
    "            Column(\"NOME_PACIENTE\", String, nullable=True),\n",
    "            Column(\"DATA_NASCIMENTO\", DateTime, nullable=True),\n",
    "            Column(\"NOME_MAE\", String, nullable=True),\n",
    "            Column(\"MUNICIPIO_RESIDENCIA\", String, nullable=True),\n",
    "            Column(\"BAIRRO_RESIDENCIA\", String, nullable=True),\n",
    "            Column(\"LOGRADOURO\", String, nullable=True),\n",
    "            Column(\"LOGRADOURO_NUMERO\", String, nullable=True),\n",
    "            Column(\"CEP\", String, nullable=True),\n",
    "            Column(\"CNS\", String, nullable=True),\n",
    "            Column(\"CPF\", String, nullable=True),\n",
    "            Column(\"CRIADO_EM\", DateTime, default=dt.datetime.now),\n",
    "            Column(\"ATUALIZADO_EM\", DateTime, default=dt.datetime.now, onupdate=dt.datetime.now),\n",
    "        )\n",
    "        # --> Data mapping (could be imported if too big)\n",
    "        mapping = {\n",
    "            \"NU_NOTIFIC\" : \"ID_SIVEP\",  \"DT_NOTIFIC\": \"DATA_NOTIFICACAO\",\n",
    "            \"NM_PACIENT\": \"NOME_PACIENTE\", \"DT_NASC\": \"DATA_NASCIMENTO\",\n",
    "            \"NM_MAE_PAC\": \"NOME_MAE\", \"CO_MUN_RES\": \"MUNICIPIO_RESIDENCIA\",\n",
    "            \"NM_BAIRRO\": \"BAIRRO_RESIDENCIA\", \"NM_LOGRADO\": \"LOGRADOURO\",\n",
    "            \"NU_NUMERO\": \"LOGRADOURO_NUMERO\", \"NU_CEP\": \"CEP\", \n",
    "            \"NU_CNS\": \"CNS\", \"NU_CPF\": \"CPF\"\n",
    "        }\n",
    "        return { tb_name : self.sivep_warehouse }, { tb_name : mapping }\n",
    "    \n",
    "class SIM:\n",
    "    def __init__(self, metadata):\n",
    "        self.metadata = metadata\n",
    "    \n",
    "    def define(self):\n",
    "        # --> Data model\n",
    "        tb_name = 'sim'\n",
    "        self.sim_warehouse = Table(\n",
    "            tb_name, self.metadata,\n",
    "            Column(\"ID_SIM\", String, primary_key=True),\n",
    "            Column(\"DATA_OBITO\", DateTime, nullable=False),\n",
    "            Column(\"NOME_PACIENTE\", String, nullable=True),\n",
    "            Column(\"DATA_NASCIMENTO\", DateTime, nullable=True),\n",
    "            Column(\"NOME_MAE\", String, nullable=True),\n",
    "            Column(\"NOME_PAI\", String, nullable=True),\n",
    "            Column(\"MUNICIPIO_RESIDENCIA\", String, nullable=True),\n",
    "            Column(\"BAIRRO_RESIDENCIA\", String, nullable=True),\n",
    "            Column(\"LOGRADOURO\", String, nullable=True),\n",
    "            Column(\"LOGRADOURO_NUMERO\", String, nullable=True),\n",
    "            Column(\"CEP\", String, nullable=True),\n",
    "            Column(\"CNS\", String, nullable=True),\n",
    "            Column(\"CPF\", String, nullable=True),\n",
    "            Column(\"CRIADO_EM\", DateTime, default=dt.datetime.now),\n",
    "            Column(\"ATUALIZADO_EM\", DateTime, default=dt.datetime.now, onupdate=dt.datetime.now),\n",
    "        )\n",
    "        # --> Data mapping (could be imported if too big)\n",
    "        mapping = {\n",
    "            \"NUMERODO\" : \"ID_SIM\",  \"DTOBITO\": \"DATA_OBITO\",\n",
    "            \"NOME\": \"NOME_PACIENTE\", \"DTNASC\": \"DATA_NASCIMENTO\",\n",
    "            \"NOME_MAE\": \"NOME_MAE\", \"CO_MUN_RES\": \"MUNICIPIO_RESIDENCIA\",\n",
    "            \"NM_BAIRRO\": \"BAIRRO_RESIDENCIA\", \"NM_LOGRADO\": \"LOGRADOURO\",\n",
    "            \"NU_NUMERO\": \"LOGRADOURO_NUMERO\", \"NU_CEP\": \"CEP\", \n",
    "            \"NU_CNS\": \"CNS\", \"NU_CPF\": \"CPF\"\n",
    "        }\n",
    "        return { tb_name : self.sivep_warehouse }, { tb_name : mapping }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f1e111-6209-4836-b1e3-aae0971b2902",
   "metadata": {},
   "source": [
    "**Datasus warehouse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "eb051682-ee7c-4999-abac-bd8573dc7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarehouseSUS:\n",
    "    '''\n",
    "        Data warehouse to store personal identification from DATASUS-specific databases.\n",
    "        \n",
    "        To assist the procedures of data matching within and between specific databases originated\n",
    "        from DATASUS information systems, this class manages the storage and also CRUD operations\n",
    "        on individual records. Only information identifying individuals in the original data are stored.\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            engine_url:\n",
    "                String. Absolute path to the warehouse database.\n",
    "                \n",
    "        Attributes:\n",
    "        -----------\n",
    "            tables:\n",
    "                Dictionary. Following a key-value schema, it stores the SQLALCHEMY data models defined for \n",
    "                the database. Keys refer to the specific data models names. \n",
    "            mappings:\n",
    "                Dictionary. Following a key-value schema, it stores the field relations between the original\n",
    "                data sources and the schema used in the data models. \n",
    "    '''\n",
    "    def __init__(self, engine_url):\n",
    "        self._engine = create_engine(engine_url)\n",
    "        self._metadata = MetaData()\n",
    "        self.tables = {}\n",
    "        self.mappings = {}\n",
    "        \n",
    "    @property\n",
    "    def engine(self):\n",
    "        return self._engine\n",
    "    \n",
    "    @engine.setter\n",
    "    def engine(self, v):\n",
    "        raise Exception()\n",
    "        \n",
    "    @property\n",
    "    def metadata(self):\n",
    "        return self._metadata\n",
    "    \n",
    "    @metadata.setter\n",
    "    def metadata(self, v):\n",
    "        raise Exception()\n",
    "        \n",
    "    # -------------------------------------------------\n",
    "        \n",
    "    def models(self):\n",
    "        # --> Get the models\n",
    "        # ----> (SIVEP-Gripe)\n",
    "        sivep_updt, sivep_mapping = SivepGripe(self._metadata).define()\n",
    "        self.tables.update(sivep_updt)\n",
    "        self.mappings.update(sivep_mapping)\n",
    "        \n",
    "    def create_all(self):\n",
    "        self._metadata.create_all(self._engine)\n",
    "        return self._engine\n",
    "    \n",
    "    def db_init(self):\n",
    "        self.models()\n",
    "        engine = self.create_all()\n",
    "        return engine\n",
    "    \n",
    "    def include(self, table_name, data_df, batchsize=50, verbose=True):\n",
    "        '''\n",
    "            Insert new records from a given dataframe.\n",
    "            \n",
    "            Args:\n",
    "            -----\n",
    "                table_name:\n",
    "                    String. Table name inside the database. Possible to extract\n",
    "                    from 'self.tables'.\n",
    "                data_df:\n",
    "                    pandas.DataFrame. Records to be inserted. Schema should match the \n",
    "                    official data sources. For instance, if the data source is SIVEP-Gripe,\n",
    "                    then the columns must match the original ones. \n",
    "                chunksize:\n",
    "                    Integer. Size of the batches of records to insert in the table.\n",
    "        '''\n",
    "        # - Load the data model and the schema mapping from 'tb_name' and rename the columns of 'data_df'\n",
    "        table_model, table_mapping = self.tables[table_name], self.mappings[table_name]\n",
    "        try:\n",
    "            data_df = data_df.rename(table_mapping, axis=1, errors='raise')\n",
    "        except:\n",
    "            Exception('Data source schema could not be properly mapped.')\n",
    "        \n",
    "        # - Define 'smart_hash' to avoid 'NaN' values in the records during insert\n",
    "        nonan_hash = smart_dict()\n",
    "        # - Perform batch insertion of records into the table.\n",
    "        data_df = data_df[ table_mapping.values() ]\n",
    "        splitted_data = np.split(data_df, np.arange(batchsize, data_df.shape[0]+1, batchsize))\n",
    "        for nindex, current_batch in enumerate(splitted_data):\n",
    "            if verbose:\n",
    "                print(f'Insertion of batch {nindex+1} of {len(splitted_data)} ... ', end='')\n",
    "            \n",
    "            # - Format records to be inserted\n",
    "            records = [ { field : nonan_hash[val] for field, val in btc.items() } for btc in current_batch.to_dict(orient='records')]\n",
    "            if len(records)==0: \n",
    "                print('no records ... done.')\n",
    "                continue\n",
    "        \n",
    "            # --> insert batch\n",
    "            try:\n",
    "                ins = table_model.insert()\n",
    "                with self._engine.connect() as conn:\n",
    "                    rp = conn.execute(ins, records)\n",
    "                    conn.commit()\n",
    "            except IntegrityError as error:\n",
    "                if verbose:\n",
    "                    print(f'error: {error.args[0]} ... ', end='')\n",
    "            \n",
    "            if verbose:\n",
    "                print('done.')\n",
    "                \n",
    "    def query(self, table_name, date_col=None, period=None):\n",
    "        '''\n",
    "            Select records from a specific table within the warehouse.\n",
    "            \n",
    "            Args:\n",
    "            -----\n",
    "                table_name:\n",
    "                    String. Table name inside the database. Possible to extract\n",
    "                    from 'self.tables'.\n",
    "                date_col:\n",
    "                    String. Column date of the table used for ordering and filtering\n",
    "                    by period (if 'period' is provided).\n",
    "                period:\n",
    "                    2-tuple of datetime.datetime. Starting and ending dates of the period\n",
    "                    selected for the query. This period is applied over the column name\n",
    "                    parsed to 'date_col' variable. If the end date is not provided, then\n",
    "                    datetime.datetime.today() is used.\n",
    "                    \n",
    "            Results:\n",
    "                results:\n",
    "                    List. List of sql table rows queried from the database. \n",
    "        '''\n",
    "        # - Load  and select the data model\n",
    "        table_model = self.tables[table_name]\n",
    "        sel = select(table_model)\n",
    "        \n",
    "        # -- Build the query\n",
    "        if date_col is not None:\n",
    "            sel = sel.order_by(table_model.c[date_col])\n",
    "            if period is not None:\n",
    "                if period[1] is None:\n",
    "                    period[1] = dt.datetime.today()\n",
    "                sel = sel.where(table_model.c[date_col].between(period[0], period[1]))\n",
    "                \n",
    "        try:\n",
    "            with engine.connect() as conn:\n",
    "                rp = conn.execute(sel)\n",
    "                results = [ record for record in rp ]\n",
    "                return results\n",
    "        except Exception as error:\n",
    "            print(error.args[0])\n",
    "            return []\n",
    "        \n",
    "    def update(self, table_name, primary_key_value, update_hash, verbose=True):\n",
    "        '''\n",
    "            Update a given record identified by its primary key value 'primary_key_value'.\n",
    "            \n",
    "            Args:\n",
    "            -----\n",
    "                table_name:\n",
    "                    String.\n",
    "                primary_key_value:\n",
    "                    String.\n",
    "                update_hash:\n",
    "                    Dictionary.\n",
    "        '''\n",
    "        # - Load the data model and define update filtering\n",
    "        table_model = self.tables[table_name]\n",
    "        primary_key_name = [ p.name for p in inspect(table_model).primary_key ][0]\n",
    "        updt = update(table_model).where(table_model.c[primary_key_name] == primary_key_value)\n",
    "        updt = updt.values(update_hash)\n",
    "        if verbose:\n",
    "            print(f'Update query: {updt} ...', end='')\n",
    "        \n",
    "        try:\n",
    "            with self._engine.connect() as conn:\n",
    "                rp = conn.execute(updt)\n",
    "                conn.commit()\n",
    "        except IntegrityError as error:\n",
    "            print(f'error: {error.args[0]}', end='')\n",
    "        \n",
    "        if verbose:\n",
    "            print(' done.')\n",
    "    \n",
    "    def delete(self, list_of_records, verbose=True):\n",
    "        '''\n",
    "            Delete a list of records from the warehouse.\n",
    "            \n",
    "            Args:\n",
    "            -----\n",
    "                list_of_records:\n",
    "                    List of unique IDs representing the primary key of the records \n",
    "                    to be deleted.\n",
    "        '''\n",
    "        # - Load the data model and extract the name of its primary key\n",
    "        table_model = self.tables[table_name]\n",
    "        primary_key_name = [ p.name for p in inspect(table_model).primary_key ][0]\n",
    "        \n",
    "        if list_of_records:\n",
    "            for nindex, current_rec in enumerate(list_of_records):\n",
    "                if verbose:\n",
    "                    print(f'Deletion of record {current_rec} ({nindex+1}/{len(list_of_records)}) ... ', end='')\n",
    "                \n",
    "                try:\n",
    "                    qdel = delete(table_model).where(table_model.c[primary_key_name]==current_rec)\n",
    "                    with self._engine.connect() as conn:\n",
    "                        rp = conn.execute(qdel)\n",
    "                        conn.commit()\n",
    "                except IntegrityError as error:\n",
    "                    if verbose:\n",
    "                        print(f'error: {error.args[0]}', end='')\n",
    "                \n",
    "                if verbose:\n",
    "                    print('done.')\n",
    "                    \n",
    "    def delete_table(self, table_name, is_sure=False, authkey=\"\"):\n",
    "        '''\n",
    "            Delete a given table from the database.\n",
    "            \n",
    "            Args:\n",
    "                table_name. String. Table name inside the database. Possible to extract\n",
    "                from 'self.tables'.\n",
    "            is_sure:\n",
    "                Bool. To delete table, it must be parsed as True.\n",
    "            pkey:\n",
    "                String. To delete table, it must be assigned to the correct string. For\n",
    "                now, it avoids accidental deletions.\n",
    "        '''\n",
    "        sql_str = f\"DROP TABLE IF EXISTS {table_name};\"\n",
    "        sql_query = text(sql_str)\n",
    "        with self._engine.connect() as conn:\n",
    "            if is_sure and authkey==\"###!Y!.\":\n",
    "                rp = conn.execute(sql_query)\n",
    "                conn.commit()\n",
    "            else:\n",
    "                raise Exception('delete table command called, but without assurance.')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "37a6df53-471b-458e-88ec-55989f40cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Paths\n",
    "basepath = os.path.join(os.environ[\"HOMEPATH\"], \"Documents\", \"data\")\n",
    "suspath = os.path.join(basepath, \"DATASUS_WAREHOUSE\", \"datasus_pessoas.db\")\n",
    "engine_url = f\"sqlite:///{suspath}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "ca151f38-fafa-45ec-9ed9-1325955c93aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse = WarehouseSUS(engine_url)\n",
    "engine = warehouse.db_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "75a070ab-28e6-4e10-b03e-0ce819a2d3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table names:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sivep_gripe']"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Table names:\")\n",
    "list(warehouse.tables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "bd5ba6d4-186d-498f-83d0-24264ad54c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT_RES_AN</th>\n",
       "      <th>RES_AN</th>\n",
       "      <th>LAB_AN</th>\n",
       "      <th>CO_LAB_AN</th>\n",
       "      <th>POS_AN_FLU</th>\n",
       "      <th>TP_FLU_AN</th>\n",
       "      <th>POS_AN_OUT</th>\n",
       "      <th>AN_SARS2</th>\n",
       "      <th>AN_VSR</th>\n",
       "      <th>AN_PARA1</th>\n",
       "      <th>...</th>\n",
       "      <th>PAC_DSCBO</th>\n",
       "      <th>OUT_ANIM</th>\n",
       "      <th>DOR_ABD</th>\n",
       "      <th>FADIGA</th>\n",
       "      <th>PERD_OLFT</th>\n",
       "      <th>PERD_PALA</th>\n",
       "      <th>TOMO_RES</th>\n",
       "      <th>TOMO_OUT</th>\n",
       "      <th>DT_TOMO</th>\n",
       "      <th>TP_TES_AN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3242</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>04/04/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DT_RES_AN RES_AN LAB_AN CO_LAB_AN POS_AN_FLU TP_FLU_AN POS_AN_OUT  \\\n",
       "834          NaN    NaN    NaN       NaN        NaN       NaN        NaN   \n",
       "3242         NaN    NaN    NaN       NaN        NaN       NaN        NaN   \n",
       "1734         NaN      5    NaN       NaN        NaN       NaN        NaN   \n",
       "2084  04/04/2023    NaN    NaN       NaN        NaN       NaN        NaN   \n",
       "\n",
       "     AN_SARS2 AN_VSR  AN_PARA1  ...  PAC_DSCBO  OUT_ANIM  DOR_ABD FADIGA  \\\n",
       "834       NaN    NaN       NaN  ...        NaN       NaN        2      2   \n",
       "3242      NaN    NaN       NaN  ...        NaN       NaN      NaN    NaN   \n",
       "1734      NaN    NaN       NaN  ...        NaN       NaN        2      2   \n",
       "2084      NaN    NaN       NaN  ...        NaN       NaN      NaN    NaN   \n",
       "\n",
       "     PERD_OLFT  PERD_PALA TOMO_RES TOMO_OUT  DT_TOMO TP_TES_AN  \n",
       "834          2          2      0.0      NaN      NaN       0.0  \n",
       "3242       NaN        NaN      0.0      NaN      NaN       0.0  \n",
       "1734         2          2      6.0      NaN      NaN       0.0  \n",
       "2084       NaN        NaN      0.0      NaN      NaN       0.0  \n",
       "\n",
       "[4 rows x 221 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df1 = sample_df.copy()\n",
    "sample_df1[\"DT_NASC\"] = pd.to_datetime(sample_df1[\"DT_NASC\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "sample_df1[\"DT_NOTIFIC\"] = pd.to_datetime(sample_df1[\"DT_NOTIFIC\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "sample_df1.sample(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "1726a5cb-3654-42a6-bff6-2f2993068cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of batch 1 of 11 ... error: (sqlite3.IntegrityError) UNIQUE constraint failed: sivep_gripe.ID_SIVEP ... done.\n",
      "Insertion of batch 2 of 11 ... error: (sqlite3.IntegrityError) UNIQUE constraint failed: sivep_gripe.ID_SIVEP ... done.\n",
      "Insertion of batch 3 of 11 ... error: (sqlite3.IntegrityError) UNIQUE constraint failed: sivep_gripe.ID_SIVEP ... done.\n",
      "Insertion of batch 4 of 11 ... error: (sqlite3.IntegrityError) UNIQUE constraint failed: sivep_gripe.ID_SIVEP ... done.\n",
      "Insertion of batch 5 of 11 ... error: (sqlite3.IntegrityError) UNIQUE constraint failed: sivep_gripe.ID_SIVEP ... done.\n",
      "Insertion of batch 6 of 11 ... error: (sqlite3.IntegrityError) UNIQUE constraint failed: sivep_gripe.ID_SIVEP ... done.\n",
      "Insertion of batch 7 of 11 ... error: (sqlite3.IntegrityError) UNIQUE constraint failed: sivep_gripe.ID_SIVEP ... done.\n",
      "Insertion of batch 8 of 11 ... error: (sqlite3.IntegrityError) UNIQUE constraint failed: sivep_gripe.ID_SIVEP ... done.\n",
      "Insertion of batch 9 of 11 ... error: (sqlite3.IntegrityError) UNIQUE constraint failed: sivep_gripe.ID_SIVEP ... done.\n",
      "Insertion of batch 10 of 11 ... error: (sqlite3.IntegrityError) UNIQUE constraint failed: sivep_gripe.ID_SIVEP ... done.\n",
      "Insertion of batch 11 of 11 ... no records ... done.\n"
     ]
    }
   ],
   "source": [
    "warehouse.include('sivep_gripe', sample_df1, batchsize=50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "9aae2ff3-040d-4a0a-bf6d-c35a27bc206a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_SIVEP</th>\n",
       "      <th>DATA_NOTIFICACAO</th>\n",
       "      <th>NOME_PACIENTE</th>\n",
       "      <th>DATA_NASCIMENTO</th>\n",
       "      <th>NOME_MAE</th>\n",
       "      <th>MUNICIPIO_RESIDENCIA</th>\n",
       "      <th>BAIRRO_RESIDENCIA</th>\n",
       "      <th>LOGRADOURO</th>\n",
       "      <th>LOGRADOURO_NUMERO</th>\n",
       "      <th>CEP</th>\n",
       "      <th>CNS</th>\n",
       "      <th>CPF</th>\n",
       "      <th>CRIADO_EM</th>\n",
       "      <th>ATUALIZADO_EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31684413073675</td>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>FRANCISCO ITAMAR BARROS NETO</td>\n",
       "      <td>1990-07-19</td>\n",
       "      <td>AURICELIA MARIA ARAUJO BARROS</td>\n",
       "      <td>230440</td>\n",
       "      <td>CJ SIQUEIRA</td>\n",
       "      <td>RUA 1 1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>04747024301</td>\n",
       "      <td>2023-07-24 15:34:42.818705</td>\n",
       "      <td>2023-07-24 15:34:42.818705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31683724910341</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>ANTONIO JOSE SILVA SANTOS</td>\n",
       "      <td>1991-10-01</td>\n",
       "      <td>MARIA LUCILENE SILVA SANTOS</td>\n",
       "      <td>231040</td>\n",
       "      <td>BELA VISTA</td>\n",
       "      <td>RUA VILA NOVA</td>\n",
       "      <td>353</td>\n",
       "      <td>None</td>\n",
       "      <td>705003045272458</td>\n",
       "      <td>05852972312</td>\n",
       "      <td>2023-07-24 15:34:42.807410</td>\n",
       "      <td>2023-07-24 15:34:42.807410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31681408558580</td>\n",
       "      <td>2023-04-13</td>\n",
       "      <td>ISRAEL RODRIGO MARTINS DOS SANTOS</td>\n",
       "      <td>1996-09-13</td>\n",
       "      <td>MARIA ALDIZIA ALVES MARTINS</td>\n",
       "      <td>230440</td>\n",
       "      <td>NOVO MONDUBIM</td>\n",
       "      <td>105 DO CONJUNTO NOVO MONDUBIM</td>\n",
       "      <td>20</td>\n",
       "      <td>60764280</td>\n",
       "      <td>707800665579718</td>\n",
       "      <td>03398363342</td>\n",
       "      <td>2023-07-24 15:34:42.832044</td>\n",
       "      <td>2023-07-24 15:34:42.832044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID_SIVEP DATA_NOTIFICACAO                      NOME_PACIENTE  \\\n",
       "0  31684413073675       2023-05-18       FRANCISCO ITAMAR BARROS NETO   \n",
       "1  31683724910341       2023-05-10          ANTONIO JOSE SILVA SANTOS   \n",
       "2  31681408558580       2023-04-13  ISRAEL RODRIGO MARTINS DOS SANTOS   \n",
       "\n",
       "  DATA_NASCIMENTO                       NOME_MAE MUNICIPIO_RESIDENCIA  \\\n",
       "0      1990-07-19  AURICELIA MARIA ARAUJO BARROS               230440   \n",
       "1      1991-10-01    MARIA LUCILENE SILVA SANTOS               231040   \n",
       "2      1996-09-13    MARIA ALDIZIA ALVES MARTINS               230440   \n",
       "\n",
       "  BAIRRO_RESIDENCIA                     LOGRADOURO LOGRADOURO_NUMERO  \\\n",
       "0       CJ SIQUEIRA                     RUA 1 1012              1012   \n",
       "1        BELA VISTA                  RUA VILA NOVA               353   \n",
       "2     NOVO MONDUBIM  105 DO CONJUNTO NOVO MONDUBIM                20   \n",
       "\n",
       "        CEP              CNS          CPF                  CRIADO_EM  \\\n",
       "0      None             None  04747024301 2023-07-24 15:34:42.818705   \n",
       "1      None  705003045272458  05852972312 2023-07-24 15:34:42.807410   \n",
       "2  60764280  707800665579718  03398363342 2023-07-24 15:34:42.832044   \n",
       "\n",
       "               ATUALIZADO_EM  \n",
       "0 2023-07-24 15:34:42.818705  \n",
       "1 2023-07-24 15:34:42.807410  \n",
       "2 2023-07-24 15:34:42.832044  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qres = warehouse.query('sivep_gripe', date_col='DATA_NASCIMENTO', period=(dt.datetime(1990,1,1), dt.datetime(1999, 12, 31)))\n",
    "pd.DataFrame(qres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "72f4350e-8c2f-4fc2-ad6b-0aa584ed61b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlalchemy.engine.row.Row"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(qres[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "c589db89-7051-46fb-b019-3e333122a770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update query: UPDATE sivep_gripe SET \"NOME_PACIENTE\"=:NOME_PACIENTE, \"DATA_NASCIMENTO\"=:DATA_NASCIMENTO, \"ATUALIZADO_EM\"=:ATUALIZADO_EM WHERE sivep_gripe.\"ID_SIVEP\" = :ID_SIVEP_1 ... done.\n"
     ]
    }
   ],
   "source": [
    "update_hash = { 'NOME_PACIENTE': 'ANTONIO JOSE SILVA SANTOX', \"DATA_NASCIMENTO\": dt.datetime(1991, 1, 1) }\n",
    "warehouse.update('sivep_gripe', '316837249103X41', update_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "62b20ea9-3a16-4cdd-9a36-47cc4e40a0aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "delete table command called, but without assurance.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [336]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mwarehouse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msivep_gripe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [326]\u001b[0m, in \u001b[0;36mWarehouseSUS.delete_table\u001b[1;34m(self, table_name, is_sure, authkey)\u001b[0m\n\u001b[0;32m    237\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete table command called, but without assurance.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: delete table command called, but without assurance."
     ]
    }
   ],
   "source": [
    "warehouse.delete_table('sivep_gripe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "191e6e35-3bab-42e0-bcda-5c17905fc507",
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse.delete_table('sivep_gripe', is_sure=True, authkey=\"###!Y!.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53473ece-d0db-4135-81e3-10bcd8404a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "64e025f9-0d49-42ef-999d-9bc54c198b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = warehouse.tables['sivep_gripe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "4a484a22-5521-4cba-96d3-378efa477c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID_SIVEP']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ n.name for n in inspect(ex).primary_key ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6fe11422-3486-4b80-8000-0e3fe4a77245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column('ID_SIVEP', String(), table=<sivep_gripe>, primary_key=True, nullable=False)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- query\n",
    "ex.c['ID_SIVEP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "730d1c48-1203-4197-88d2-3faebca361ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_model = warehouse.tables['sivep_gripe']\n",
    "sel = select(table_model).order_by(table_model.c[\"DATA_NOTIFICACAO\"])\n",
    "period = None\n",
    "col_date_filter = None #\"DATA_NOTIFICACAO\"\n",
    "        \n",
    "# -- Build the query\n",
    "if col_date_filter is not None:\n",
    "    sel = sel.order_by(table_model.c[col_date_filter])\n",
    "    if period is not None:\n",
    "        sel = sel.where(table_model.c[col_date_filter].between(period[0], period[1]))\n",
    "\n",
    "results = []        \n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        rp = conn.execute(sel)\n",
    "        #results = rp.fetchall()\n",
    "        results = [ record for record in rp ]\n",
    "        #return results\n",
    "except Exception as error:\n",
    "    print(error.args[0])\n",
    "    #return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "78e89847-fa90-4327-978f-9a42e1c9707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "c32024ec-2a32-43c4-9a4e-359e35a27c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************* DELETE **************\n",
    "sqlt = text('DROP TABLE IF EXISTS sivep_gripe;')\n",
    "with engine.connect() as conn:\n",
    "    rp = conn.execute(sqlt)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014648e6-3414-4206-849e-f2652b8a85dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "647a3669-c7b1-4394-bdd7-16a15004f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823f331-ee68-4e23-9b93-3829a2b4e30e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
